<div class="pi_robot">
  <div class="container">
    <div class="section_title">
      <h1>Raspberry Pi Robot</h1>
    </div>
    <div class="row">
      <section class="col-md-6">
        <div class="poster_title">Introduction
          <span class="poster_number">1</span>
        </div>
        <div class="poster_content">
          <p>
            This poster describes the design and construction of a
            robotic mapping tool based on a Raspberry Pi. The tool uses
            sonar information to incrementally improve its model of the
            environment. Data is streamed to a laptop so that a live map
            can be viewed, as well as preliminary processing steps
          </p>
        </div>
      </section>
      <section class="col-md-6">
        <div class="poster_title">Motivations 
          <span class="poster_number">2</span>
        </div>
        <div class="poster_content">
          <p>
            Simultaneous Localisation and Mapping (SLAM) is a widely
            researched field, there are limitations in using it to produce
            real-time maps <b>[1]</b>, especially with cheap components.
            This project aims to develop a SLAM controlled mobile robot
            that displays a live map on a laptop, using basic component
          </p>
        </div>
      </section>
      <section class="col-md-5">
        <div class="poster_title">SLAM 
          <span class="poster_number">3</span>
        </div>
        <div class="poster_content">
          <p>
            SLAM is the process of consolidating
            sequential error-prone data - odometry
            and sonar in this project - into a
            map of an environment, which is a
            2-dimensional occupancy grid <b>[2]</b> in
            this project. The diagrams below the
            type of error that should be fixed. In
            (a), two landmarks are detected <b>[3]</b>,
            stored as line segments. (b) shows the
            robot attempting to move in a straight
            line. In (c), Two new landmarks are
            detected, appearing out of place from
            the previous ones. The actual position
            of the robot is shown in (d).
          </p>
          <img width="100%" src="assets/images/projects/raspberry-pi-robot/slam.png" />
        </div>
      </section>
      <section class="col-md-7">
        <div class="poster_title">The Robot 
          <span class="poster_number">4</span>
        </div>
        <div class="poster_content">
          <p>
            The robot is constructed using a
            Raspberry Pi, a BrickPi, and LEGO
            sensors and parts. The sensors rotate to
            give a full 360ยบ view of the environment.
            A naive estimate of the robot's state is
            calculated locally, and this, along with
            sensor information, is streamed to a
            laptop via a web socket.
          </p>
          <img width="100%" src="assets/images/projects/raspberry-pi-robot/robot.png" />
        </div>
      </section>
      <section class="col-md-6">
        <div class="poster_title">The Tool 
          <span class="poster_number">5</span>
        </div>
        <div class="poster_content">
          <p>
            The tool displays a live map, the
            robot's naive position, and the robot's
            SLAM adjusted position. Preliminary
            probability information can be overlaid
            to gain insight into the SLAM process,
            seen in the images below:
          </p>
          <img width="100%" style="margin-bottom: 10px;" src="assets/images/projects/raspberry-pi-robot/the-tool-1.png" />
          <p>
            Parameters can be using settings
            within the tool, shown below
          </p>
          <img width="100%" src="assets/images/projects/raspberry-pi-robot/the-tool-3.png" />
        </div>
      </section>
      <section class="col-md-6">
        <div class="poster_title">Results 
          <span class="poster_number">6</span>
        </div>
        <div class="poster_content">
          <p>
            (a) shows the errors that occur in the sonar sensor data, when the robot is near a
            corner. It can be seen that, near the corner, measurements take values further than
            the walls, but take values closer to the walls otherwise. This gives an idea of the sort
            of errors that must be fixed by SLAM.
            The solution improves the robot's estimate of its position, compared to naive
            estimation. (b) shows how the ratio of SLAM error to naive error changes, and shows
            that the error is kept low. It can be seen in (c) that the use of SLAM makes a vast
            improvement to the robot's estimate of location, compared to the naive estimation
            shown in (d).
          </p>
          <img width="100%" src="assets/images/projects/raspberry-pi-robot/results.png" />
        </div>
      </section>
      <section class="col-md-7">
        <div class="poster_title">Conclusions <span class="poster_number">7</span></div>
        <div class="poster_content">
          <p>
            A robot, map visualisation tool, and SLAM algorithm, were successfully produced.
            The algorithm provides large improvements to the estimation of the robot's state,
            although it has limtations in larger environments. Short term. the solution could
            be improved using better landmark and detection, and processing of sensor data.
            Since the solution is limited by the sensor quality, other ways of data collection
            would be explored longer term, for example mobile phones. Phones are cheap,
            and provide compass, gyroscopic, camera, etc. data, making
            them ideal for SLAM.
          </p>
        </div>
      </section>
      <section class="col-md-5">
        <div class="poster_title">References 
          <span class="poster_number">8</span>
        </div>
        <div class="poster_content">
          <p>
            <b>[1]</b> Thrun, S. (2002), "Robotic mapping: A survey",
            Exploring artificial intelligence in
            the new millennium 1, 1-35.
          </p>
          <p>
            <b>[2]</b> Elfes, A. (1989), "Using occupancy grids
            for mobile robot perception and navigation".
          </p>
          <p>
            <b>[3]</b> Hough, P. V. C. (1962), "Method and
            means for recognizing complex patterns".
          </p>
        </div>
      </section>
    </div>
  </div>
</div>